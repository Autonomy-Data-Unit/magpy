{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "64c608f0",
            "metadata": {},
            "source": [
                "# magpy\n",
                "\n",
                "> A powerful Python library for extracting structured data from unstructured text using Large Language Models (LLMs). magpy provides a simple, flexible interface for converting free-form text into structured, machine-readable data formats."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b9efd94",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|hide\n",
                "import nblite; from nbdev.showdoc import show_doc; nblite.nbl_export()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "16ab6704",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|hide\n",
                "import magpy as proj"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "19418eca",
            "metadata": {},
            "source": [
                "## Installation\n",
                "\n",
                "```bash\n",
                "pip install git+https://github.com/Autonomy-Data-Unit/magpy\n",
                "```\n",
                "\n",
                "## Quick Start\n",
                "\n",
                "For detailed examples see the [examples](./nbs/examples/) folder.\n",
                "\n",
                "### Basic Usage\n",
                "\n",
                "```python\n",
                "from magpy import extract_structured, set_magpy_config\n",
                "import os\n",
                "\n",
                "# Configure the LLM\n",
                "set_magpy_config(\n",
                "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
                "    model_name=\"gpt-4o\",    \n",
                "    temperature=0.1,\n",
                "    cache_path='.cache'\n",
                ")\n",
                "\n",
                "# Define your extraction schema\n",
                "schema = {\n",
                "    \"name\": str,\n",
                "    \"amount\": int,\n",
                "    \"date\": datetime,\n",
                "    \"category\": str\n",
                "}\n",
                "\n",
                "# Extract structured data from text\n",
                "text = \"John Doe donated $500 to the charity on 2024-01-15 for education programs.\"\n",
                "result = extract_structured(text=text, schema=schema)\n",
                "print(result)\n",
                "# Output: {'name': 'John Doe', 'amount': 500, 'date': datetime(2024, 1, 15), 'category': 'education'}\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4c08ac53",
            "metadata": {},
            "source": [
                "## Contributing\n",
                "\n",
                "To contribute to the development of the package, follow the below instructions.\n",
                "\n",
                "### Prerequisites\n",
                "\n",
                "- Install [uv](https://docs.astral.sh/uv/getting-started/installation/).\n",
                "- Install [direnv](https://direnv.net/) to automatically load the project virtual environment when entering it.\n",
                "    - Mac: `brew install direnv`\n",
                "    - Linux: `curl -sfL https://direnv.net/install.sh | bash`\n",
                "\n",
                "### Setting up the environment\n",
                "\n",
                "Run the following:\n",
                "\n",
                "```bash\n",
                "# In the root of the repo folder\n",
                "uv sync --all-extras # Installs the virtual environment at './.venv'\n",
                "direnv allow # Allows the automatic running of the script './.envrc'\n",
                "nbl install-hooks # Installs a git hooks that ensures that notebooks are added properly\n",
                "```\n",
                "\n",
                "You are now set up to develop the codebase.\n",
                "\n",
                "Further instructions:\n",
                "\n",
                "- To export notebooks run `nbl export`.\n",
                "- To clean notebooks run `nbl clean`.\n",
                "- To see other available commands run just `nbl`.\n",
                "- To add a new dependency run `uv add package-name`. See the the [uv documentation](https://docs.astral.sh/uv/) for more details.\n",
                "- You need to `git add` all 'twinned' notebooks for the commit to be validated by the git-hook. For example, if you add `nbs/my-nb.ipynb`, you must also add `pts/my-nb.pct.py`.\n",
                "- To render the documentation, run `nbl render-docs`. To preview it run `nbl preview-docs`\n",
                "- To upgrade all dependencies run `uv sync --upgrade --all-extras`\n",
                "<!-- #endregion -->\n",
                "\n",
                "## Support\n",
                "\n",
                "For questions, issues, or contributions, please open an issue on the GitHub repository."
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "main_language": "python",
            "notebook_metadata_filter": "-all"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "nblite_source_hash": "2cdf4bb96b79707ab171f778d7e35ec8b09a2b3c44a672165fdb93f2cfa9dc58"
    },
    "nbformat": 4,
    "nbformat_minor": 5
}